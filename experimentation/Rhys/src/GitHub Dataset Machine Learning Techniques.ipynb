{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Machine Learning Techniques for GitHub Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/radon-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>radon</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>tvoc</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>state</th>\n",
       "      <th>state_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21906</td>\n",
       "      <td>1569405062</td>\n",
       "      <td>202</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Off</td>\n",
       "      <td>1569404979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21907</td>\n",
       "      <td>1569405663</td>\n",
       "      <td>258</td>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>On</td>\n",
       "      <td>1569405215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21908</td>\n",
       "      <td>1569406264</td>\n",
       "      <td>202</td>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Off</td>\n",
       "      <td>1569405671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21909</td>\n",
       "      <td>1569406865</td>\n",
       "      <td>182</td>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Off</td>\n",
       "      <td>1569406848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21910</td>\n",
       "      <td>1569407466</td>\n",
       "      <td>189</td>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Off</td>\n",
       "      <td>1569406866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87965</th>\n",
       "      <td>138640</td>\n",
       "      <td>1622736862</td>\n",
       "      <td>1344</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>Off</td>\n",
       "      <td>1622736447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87966</th>\n",
       "      <td>138642</td>\n",
       "      <td>1622737462</td>\n",
       "      <td>1293</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>Off</td>\n",
       "      <td>1622736963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87967</th>\n",
       "      <td>138644</td>\n",
       "      <td>1622738063</td>\n",
       "      <td>1223</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>Off</td>\n",
       "      <td>1622736963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87968</th>\n",
       "      <td>138646</td>\n",
       "      <td>1622738663</td>\n",
       "      <td>1171</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>Off</td>\n",
       "      <td>1622738463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87969</th>\n",
       "      <td>138648</td>\n",
       "      <td>1622739264</td>\n",
       "      <td>1127</td>\n",
       "      <td>22</td>\n",
       "      <td>44</td>\n",
       "      <td>1018</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>Off</td>\n",
       "      <td>1622738463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87970 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        time  radon  temperature  humidity  pressure  tvoc  \\\n",
       "0       21906  1569405062    202           25        50      1015     0   \n",
       "1       21907  1569405663    258           25        51      1015     0   \n",
       "2       21908  1569406264    202           24        51      1015     0   \n",
       "3       21909  1569406865    182           24        51      1015     0   \n",
       "4       21910  1569407466    189           24        51      1015     0   \n",
       "...       ...         ...    ...          ...       ...       ...   ...   \n",
       "87965  138640  1622736862   1344           22        43      1018    23   \n",
       "87966  138642  1622737462   1293           22        43      1018    34   \n",
       "87967  138644  1622738063   1223           22        43      1018    34   \n",
       "87968  138646  1622738663   1171           22        43      1018    34   \n",
       "87969  138648  1622739264   1127           22        44      1018    26   \n",
       "\n",
       "       sensor_id state  state_time  \n",
       "0              2   Off  1569404979  \n",
       "1              2    On  1569405215  \n",
       "2              2   Off  1569405671  \n",
       "3              2   Off  1569406848  \n",
       "4              2   Off  1569406866  \n",
       "...          ...   ...         ...  \n",
       "87965          2   Off  1622736447  \n",
       "87966          2   Off  1622736963  \n",
       "87967          2   Off  1622736963  \n",
       "87968          2   Off  1622738463  \n",
       "87969          2   Off  1622738463  \n",
       "\n",
       "[87970 rows x 10 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radon</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>tvoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202</td>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182</td>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189</td>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87965</th>\n",
       "      <td>1344</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87966</th>\n",
       "      <td>1293</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87967</th>\n",
       "      <td>1223</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87968</th>\n",
       "      <td>1171</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87969</th>\n",
       "      <td>1127</td>\n",
       "      <td>22</td>\n",
       "      <td>44</td>\n",
       "      <td>1018</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87970 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       radon  temperature  humidity  pressure  tvoc\n",
       "0        202           25        50      1015     0\n",
       "1        258           25        51      1015     0\n",
       "2        202           24        51      1015     0\n",
       "3        182           24        51      1015     0\n",
       "4        189           24        51      1015     0\n",
       "...      ...          ...       ...       ...   ...\n",
       "87965   1344           22        43      1018    23\n",
       "87966   1293           22        43      1018    34\n",
       "87967   1223           22        43      1018    34\n",
       "87968   1171           22        43      1018    34\n",
       "87969   1127           22        44      1018    26\n",
       "\n",
       "[87970 rows x 5 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[\"time\", \"state_time\", \"id\", \"sensor_id\", \"state\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df['state'] = df['state'].replace({'Off': 0, 'On': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radon</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>tvoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202</td>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182</td>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189</td>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87965</th>\n",
       "      <td>1344</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87966</th>\n",
       "      <td>1293</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87967</th>\n",
       "      <td>1223</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87968</th>\n",
       "      <td>1171</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87969</th>\n",
       "      <td>1127</td>\n",
       "      <td>22</td>\n",
       "      <td>44</td>\n",
       "      <td>1018</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87970 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       radon  temperature  humidity  pressure  tvoc\n",
       "0        202           25        50      1015     0\n",
       "1        258           25        51      1015     0\n",
       "2        202           24        51      1015     0\n",
       "3        182           24        51      1015     0\n",
       "4        189           24        51      1015     0\n",
       "...      ...          ...       ...       ...   ...\n",
       "87965   1344           22        43      1018    23\n",
       "87966   1293           22        43      1018    34\n",
       "87967   1223           22        43      1018    34\n",
       "87968   1171           22        43      1018    34\n",
       "87969   1127           22        44      1018    26\n",
       "\n",
       "[87970 rows x 5 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radon</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>tvoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36000</th>\n",
       "      <td>388</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>1010</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36001</th>\n",
       "      <td>383</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>1010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36002</th>\n",
       "      <td>398</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>1010</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36003</th>\n",
       "      <td>388</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>1010</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36004</th>\n",
       "      <td>388</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>1010</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       radon  temperature  humidity  pressure  tvoc\n",
       "36000    388           24        57      1010     4\n",
       "36001    383           24        57      1010     2\n",
       "36002    398           24        57      1010     6\n",
       "36003    388           24        57      1010     8\n",
       "36004    388           24        57      1010    10"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summer = df.iloc[36000:48000]\n",
    "df_summer.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df = df.drop(columns=[\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radon</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>tvoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36000</th>\n",
       "      <td>388</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>1010</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36001</th>\n",
       "      <td>383</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>1010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36002</th>\n",
       "      <td>398</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>1010</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36003</th>\n",
       "      <td>388</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>1010</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36004</th>\n",
       "      <td>388</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>1010</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47995</th>\n",
       "      <td>172</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>1011</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47996</th>\n",
       "      <td>168</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>1011</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47997</th>\n",
       "      <td>202</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>1011</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47998</th>\n",
       "      <td>202</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>1011</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47999</th>\n",
       "      <td>222</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>1010</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       radon  temperature  humidity  pressure  tvoc\n",
       "36000    388           24        57      1010     4\n",
       "36001    383           24        57      1010     2\n",
       "36002    398           24        57      1010     6\n",
       "36003    388           24        57      1010     8\n",
       "36004    388           24        57      1010    10\n",
       "...      ...          ...       ...       ...   ...\n",
       "47995    172           26        52      1011    63\n",
       "47996    168           26        52      1011    65\n",
       "47997    202           26        52      1011    62\n",
       "47998    202           26        52      1011    54\n",
       "47999    222           26        52      1010    51\n",
       "\n",
       "[12000 rows x 5 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radon</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>tvoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36000</th>\n",
       "      <td>0.119640</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36001</th>\n",
       "      <td>0.117911</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36002</th>\n",
       "      <td>0.123098</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36003</th>\n",
       "      <td>0.119640</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.006926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36004</th>\n",
       "      <td>0.119640</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.008658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          radon  temperature  humidity  pressure      tvoc\n",
       "36000  0.119640     0.714286  0.666667       0.5  0.003463\n",
       "36001  0.117911     0.714286  0.666667       0.5  0.001732\n",
       "36002  0.123098     0.714286  0.666667       0.5  0.005195\n",
       "36003  0.119640     0.714286  0.666667       0.5  0.006926\n",
       "36004  0.119640     0.714286  0.666667       0.5  0.008658"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summer_min = df_summer.min() # needed to de-normalize data\n",
    "summer_max = df_summer.max()\n",
    "\n",
    "df_summer_normalized = (df_summer - summer_min) / (summer_max - summer_min)\n",
    "df_summer_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_summer_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radon</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>tvoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36000</th>\n",
       "      <td>0.119640</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.003463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36001</th>\n",
       "      <td>0.117911</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36002</th>\n",
       "      <td>0.123098</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36003</th>\n",
       "      <td>0.119640</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.006926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36004</th>\n",
       "      <td>0.119640</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.008658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47995</th>\n",
       "      <td>0.044952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.054545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47996</th>\n",
       "      <td>0.043568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.056277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47997</th>\n",
       "      <td>0.055325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.053680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47998</th>\n",
       "      <td>0.055325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.046753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47999</th>\n",
       "      <td>0.062241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.044156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          radon  temperature  humidity  pressure      tvoc\n",
       "36000  0.119640     0.714286  0.666667  0.500000  0.003463\n",
       "36001  0.117911     0.714286  0.666667  0.500000  0.001732\n",
       "36002  0.123098     0.714286  0.666667  0.500000  0.005195\n",
       "36003  0.119640     0.714286  0.666667  0.500000  0.006926\n",
       "36004  0.119640     0.714286  0.666667  0.500000  0.008658\n",
       "...         ...          ...       ...       ...       ...\n",
       "47995  0.044952     1.000000  0.481481  0.541667  0.054545\n",
       "47996  0.043568     1.000000  0.481481  0.541667  0.056277\n",
       "47997  0.055325     1.000000  0.481481  0.541667  0.053680\n",
       "47998  0.055325     1.000000  0.481481  0.541667  0.046753\n",
       "47999  0.062241     1.000000  0.481481  0.500000  0.044156\n",
       "\n",
       "[12000 rows x 5 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Model Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination of independent variables: ('temperature', 'pressure', 'tvoc')\n",
      "Highest R-squared score: 0.029810351158771287\n"
     ]
    }
   ],
   "source": [
    "independent_vars = [\"temperature\", \"humidity\", \"pressure\", \"tvoc\"]\n",
    "\n",
    "# Function to get all combinations of the independent variables\n",
    "def all_combinations(variables):\n",
    "    return list(chain(*map(lambda x: combinations(variables, x), range(1, len(variables) + 1))))\n",
    "\n",
    "# Get all combinations of independent variables\n",
    "combinations = all_combinations(independent_vars)\n",
    "\n",
    "# Dependent variable\n",
    "dependent_var = \"radon\"\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[independent_vars], df[dependent_var], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a dictionary to store R-squared scores\n",
    "r2_scores = {}\n",
    "\n",
    "# Iterate over each combination of independent variables\n",
    "for combo in combinations:\n",
    "    # Train a linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train[list(combo)], y_train)\n",
    "\n",
    "    # Make predictions using the test set\n",
    "    y_pred = model.predict(X_test[list(combo)])\n",
    "\n",
    "    # Calculate R-squared score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Store the R-squared score in the dictionary\n",
    "    r2_scores[combo] = r2\n",
    "\n",
    "# Find the combination with the highest R-squared score\n",
    "best_combo = max(r2_scores, key=r2_scores.get)\n",
    "\n",
    "print(\"Best combination of independent variables:\", best_combo)\n",
    "print(\"Highest R-squared score:\", r2_scores[best_combo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3717580959030975\n"
     ]
    }
   ],
   "source": [
    "df_logistic_reg = pd.read_csv('../data/radon-data.csv')\n",
    "df_logistic_reg = df_logistic_reg.drop(columns=[\"time\", \"state_time\", \"id\", \"sensor_id\"])\n",
    "df_logistic_reg['state'] = df_logistic_reg['state'].replace({'Off': 0, 'On': 1})\n",
    "df_logistic_reg['radon_binary'] = df_logistic_reg['radon'].apply(lambda x: 1 if x > 300 else 0)\n",
    "correlation = df_logistic_reg['radon_binary'].corr(df_logistic_reg['state'])\n",
    "print(correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>tvoc</th>\n",
       "      <th>state</th>\n",
       "      <th>radon_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87965</th>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87966</th>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87967</th>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87968</th>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>1018</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87969</th>\n",
       "      <td>22</td>\n",
       "      <td>44</td>\n",
       "      <td>1018</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87970 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temperature  humidity  pressure  tvoc  state  radon_binary\n",
       "0               25        50      1015     0      0             0\n",
       "1               25        51      1015     0      1             0\n",
       "2               24        51      1015     0      0             0\n",
       "3               24        51      1015     0      0             0\n",
       "4               24        51      1015     0      0             0\n",
       "...            ...       ...       ...   ...    ...           ...\n",
       "87965           22        43      1018    23      0             1\n",
       "87966           22        43      1018    34      0             1\n",
       "87967           22        43      1018    34      0             1\n",
       "87968           22        43      1018    34      0             1\n",
       "87969           22        44      1018    26      0             1\n",
       "\n",
       "[87970 rows x 6 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_logistic_reg['radon_binary'] = df_logistic_reg['radon'].apply(lambda x: 1 if x > 300 else 0)\n",
    "df_logistic_reg = df_logistic_reg.drop(columns=[\"radon\"])\n",
    "df_logistic_reg\n",
    "##correlation = df_logistic_reg['radon_binary'].corr(df_logistic_reg['state'])\n",
    "##print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression: Model Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination of independent variables: ('temperature', 'state')\n",
      "Highest accuracy score: 0.7175741730135273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import chain, combinations\n",
    "\n",
    "# Independent variables\n",
    "independent_vars = [\"temperature\", \"humidity\", \"pressure\", \"tvoc\", \"state\"]\n",
    "\n",
    "# Function to get all combinations of the independent variables\n",
    "def all_combinations(variables):\n",
    "    return list(chain(*map(lambda x: combinations(variables, x), range(1, len(variables) + 1))))\n",
    "\n",
    "# Get all combinations of independent variables\n",
    "combinations = all_combinations(independent_vars)\n",
    "\n",
    "# Dependent variable\n",
    "dependent_var = \"radon_binary\"\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_logistic_reg[independent_vars], df_logistic_reg[dependent_var], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a dictionary to store accuracy scores\n",
    "accuracy_scores = {}\n",
    "\n",
    "# Iterate over each combination of independent variables\n",
    "for combo in combinations:\n",
    "    # Train a logistic regression model\n",
    "    model = LogisticRegression(max_iter=1000) # Increase max_iter if the algorithm does not converge\n",
    "    model.fit(X_train[list(combo)], y_train)\n",
    "\n",
    "    # Make predictions using the test set\n",
    "    y_pred = model.predict(X_test[list(combo)])\n",
    "\n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Store the accuracy score in the dictionary\n",
    "    accuracy_scores[combo] = accuracy\n",
    "\n",
    "# Find the combination with the highest accuracy score\n",
    "best_combo = max(accuracy_scores, key=accuracy_scores.get)\n",
    "\n",
    "print(\"Best combination of independent variables:\", best_combo)\n",
    "print(\"Highest accuracy score:\", accuracy_scores[best_combo])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[249], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(chain(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: combinations(variables, x), \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(variables) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))))\n\u001b[1;32m     12\u001b[0m \u001b[39m# Get all combinations of independent variables\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m combinations \u001b[39m=\u001b[39m all_combinations(independent_vars)\n\u001b[1;32m     15\u001b[0m \u001b[39m# Dependent variable\u001b[39;00m\n\u001b[1;32m     16\u001b[0m dependent_var \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mradon_binary\u001b[39m\u001b[39m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[249], line 10\u001b[0m, in \u001b[0;36mall_combinations\u001b[0;34m(variables)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mall_combinations\u001b[39m(variables):\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(chain(\u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(\u001b[39mlambda\u001b[39;49;00m x: combinations(variables, x), \u001b[39mrange\u001b[39;49m(\u001b[39m1\u001b[39;49m, \u001b[39mlen\u001b[39;49m(variables) \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m))))\n",
      "Cell \u001b[0;32mIn[249], line 10\u001b[0m, in \u001b[0;36mall_combinations.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mall_combinations\u001b[39m(variables):\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(chain(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: combinations(variables, x), \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(variables) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Independent variables\n",
    "independent_vars = [\"temperature\", \"humidity\", \"pressure\", \"tvoc\", \"state\"]\n",
    "\n",
    "# Function to get all combinations of the independent variables\n",
    "def all_combinations(variables):\n",
    "    return list(chain(*map(lambda x: combinations(variables, x), range(1, len(variables) + 1))))\n",
    "\n",
    "# Get all combinations of independent variables\n",
    "combinations = all_combinations(independent_vars)\n",
    "\n",
    "# Dependent variable\n",
    "dependent_var = \"radon_binary\"\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_logistic_reg[independent_vars], df_logistic_reg[dependent_var], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a dictionary to store accuracy scores\n",
    "accuracy_scores = {}\n",
    "\n",
    "# Iterate over each combination of independent variables\n",
    "for combo in combinations:\n",
    "    # Train a logistic regression model\n",
    "    model = LinearRegression(max_iter=1000) # Increase max_iter if the algorithm does not converge\n",
    "    model.fit(X_train[list(combo)], y_train)\n",
    "\n",
    "    # Make predictions using the test set\n",
    "    y_pred = model.predict(X_test[list(combo)])\n",
    "\n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Store the accuracy score in the dictionary\n",
    "    accuracy_scores[combo] = accuracy\n",
    "\n",
    "# Find the combination with the highest accuracy score\n",
    "best_combo = max(accuracy_scores, key=accuracy_scores.get)\n",
    "\n",
    "print(\"Best combination of independent variables:\", best_combo)\n",
    "print(\"Highest accuracy score:\", accuracy_scores[best_combo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network: Model Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination of independent variables: ('temperature', 'humidity', 'pressure', 'state')\n",
      "Highest R-squared score: 0.2045970236774428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from itertools import chain, combinations\n",
    "\n",
    "\n",
    "# Independent variables\n",
    "independent_vars = [\"temperature\", \"humidity\", \"pressure\", \"tvoc\", \"state\"]\n",
    "\n",
    "# Function to get all combinations of the independent variables\n",
    "def all_combinations(variables):\n",
    "    return list(chain(*map(lambda x: combinations(variables, x), range(1, len(variables) + 1))))\n",
    "\n",
    "# Get all combinations of independent variables\n",
    "combinations = all_combinations(independent_vars)\n",
    "\n",
    "# Dependent variable\n",
    "dependent_var = \"radon\"\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[independent_vars], df[dependent_var], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a dictionary to store R-squared scores\n",
    "r2_scores = {}\n",
    "\n",
    "# Iterate over each combination of independent variables\n",
    "for combo in combinations:\n",
    "    # Train a neural network regression model\n",
    "    model = MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=500, random_state=42) # Adjust hyperparameters as needed\n",
    "    model.fit(X_train[list(combo)], y_train)\n",
    "\n",
    "    # Make predictions using the test set\n",
    "    y_pred = model.predict(X_test[list(combo)])\n",
    "\n",
    "    # Calculate R-squared score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Store the R-squared score in a dictionary\n",
    "    r2_scores[combo] = r2\n",
    "    \n",
    "    #Find the combination with the highest R-squared score\n",
    "    best_combo = max(r2_scores, key=r2_scores.get)\n",
    "\n",
    "print(\"Best combination of independent variables:\", best_combo)\n",
    "print(\"Highest R-squared score:\", r2_scores[best_combo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radon</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>tvoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36000</th>\n",
       "      <td>0.119640</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.003463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36001</th>\n",
       "      <td>0.117911</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36002</th>\n",
       "      <td>0.123098</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36003</th>\n",
       "      <td>0.119640</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.006926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36004</th>\n",
       "      <td>0.119640</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.008658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47995</th>\n",
       "      <td>0.044952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.054545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47996</th>\n",
       "      <td>0.043568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.056277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47997</th>\n",
       "      <td>0.055325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.053680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47998</th>\n",
       "      <td>0.055325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.046753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47999</th>\n",
       "      <td>0.062241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.044156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          radon  temperature  humidity  pressure      tvoc\n",
       "36000  0.119640     0.714286  0.666667  0.500000  0.003463\n",
       "36001  0.117911     0.714286  0.666667  0.500000  0.001732\n",
       "36002  0.123098     0.714286  0.666667  0.500000  0.005195\n",
       "36003  0.119640     0.714286  0.666667  0.500000  0.006926\n",
       "36004  0.119640     0.714286  0.666667  0.500000  0.008658\n",
       "...         ...          ...       ...       ...       ...\n",
       "47995  0.044952     1.000000  0.481481  0.541667  0.054545\n",
       "47996  0.043568     1.000000  0.481481  0.541667  0.056277\n",
       "47997  0.055325     1.000000  0.481481  0.541667  0.053680\n",
       "47998  0.055325     1.000000  0.481481  0.541667  0.046753\n",
       "47999  0.062241     1.000000  0.481481  0.500000  0.044156\n",
       "\n",
       "[12000 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees: Model Train/Test w/Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316], got [0.         0.00138313 0.00207469 0.00276625 0.00345781 0.00414938\n 0.00484094 0.0055325  0.00622407 0.00691563 0.00760719 0.00829876\n 0.00899032 0.0093361  0.01037344 0.01106501 0.01141079 0.01210235\n 0.01279391 0.01348548 0.01417704 0.0148686  0.01556017 0.01625173\n 0.01694329 0.01763485 0.01832642 0.01901798 0.01970954 0.02040111\n 0.02109267 0.02178423 0.0224758  0.02316736 0.02385892 0.02455048\n 0.02524205 0.02558783 0.02662517 0.02697095 0.02766252 0.02869986\n 0.02904564 0.02973721 0.03042877 0.03112033 0.03181189 0.03250346\n 0.03319502 0.03388658 0.03457815 0.03526971 0.03596127 0.03665284\n 0.0373444  0.03803596 0.03872752 0.03941909 0.04011065 0.04080221\n 0.04149378 0.04218534 0.0428769  0.04356846 0.04426003 0.04495159\n 0.04564315 0.04633472 0.04702628 0.04771784 0.04840941 0.04910097\n 0.04979253 0.05048409 0.05117566 0.05186722 0.05255878 0.05325035\n 0.05394191 0.05463347 0.05532503 0.0560166  0.05670816 0.05739972\n 0.05809129 0.05878285 0.05947441 0.06016598 0.06085754 0.0615491\n 0.06224066 0.06293223 0.06362379 0.06431535 0.06500692 0.06569848\n 0.06639004 0.0670816  0.06777317 0.06846473 0.06915629 0.06984786\n 0.07053942 0.07123098 0.07192254 0.07261411 0.07330567 0.07399723\n 0.0746888  0.07538036 0.07607192 0.07676349 0.07745505 0.07814661\n 0.07883817 0.07987552 0.0802213  0.08125864 0.08160443 0.08264177\n 0.08333333 0.0840249  0.08471646 0.08540802 0.08609959 0.08679115\n 0.08748271 0.08817427 0.08886584 0.0895574  0.09024896 0.09094053\n 0.09163209 0.09232365 0.09301521 0.09370678 0.09439834 0.0950899\n 0.09578147 0.09647303 0.09751037 0.09785615 0.0988935  0.09958506\n 0.09993084 0.10096819 0.10165975 0.10235131 0.10304288 0.10373444\n 0.104426   0.10511757 0.10580913 0.10650069 0.10719225 0.10788382\n 0.10857538 0.10926694 0.11030429 0.11065007 0.11168741 0.11237898\n 0.11272476 0.1137621  0.11445367 0.11514523 0.11583679 0.11652835\n 0.11721992 0.11791148 0.11860304 0.11964039 0.11998617 0.12102351\n 0.12171508 0.12240664 0.1230982  0.12378976 0.12448133 0.12517289\n 0.12586445 0.12655602 0.12759336 0.12793914 0.12897649 0.12966805\n 0.13035961 0.13105118 0.13174274 0.1324343  0.13312586 0.13381743\n 0.13450899 0.13554633 0.1362379  0.13692946 0.13762102 0.13831259\n 0.13900415 0.13969571 0.14038728 0.14107884 0.1417704  0.14280775\n 0.14349931 0.14419087 0.14488243 0.145574   0.14626556 0.14695712\n 0.14764869 0.14868603 0.14903181 0.15006916 0.15076072 0.15145228\n 0.15214385 0.15283541 0.15352697 0.15421853 0.1549101  0.15594744\n 0.156639   0.15733057 0.15802213 0.15871369 0.15940526 0.16009682\n 0.16113416 0.16182573 0.16251729 0.16320885 0.16390041 0.16459198\n 0.16528354 0.16632089 0.16701245 0.16770401 0.16839557 0.16908714\n 0.1697787  0.17047026 0.17116183 0.17219917 0.17289073 0.1735823\n 0.17427386 0.17496542 0.17565698 0.17669433 0.17738589 0.17807746\n 0.17876902 0.17946058 0.18015214 0.18395574 0.1846473  0.18568465\n 0.18637621 0.1884509  0.18914246 0.19605809 0.20366528 0.21196404\n 0.21887967 0.24757953 0.25311203 0.29253112 0.32261411 0.34163209\n 0.34232365 0.36825726 0.39211618 0.41251729 0.4291148  0.44156293\n 0.46473029 0.47268326 0.47994467 0.48720609 0.48962656 0.49723375\n 0.51106501 0.52489627 0.55843707 0.58748271 0.61272476 0.6137621\n 0.61964039 0.63416321 0.64211618 0.66735823 0.67116183 0.67219917\n 0.69502075 0.71749654 0.73858921 0.75103734 0.75207469 0.75622407\n 0.78526971 0.80152144 0.81051176 0.84024896 0.87828492 0.88070539\n 0.90698479 0.92427386 0.9253112  0.93257261 0.94640387 0.95470263\n 0.9664592  0.96991701 0.97233748 0.97614108 1.        ]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311], got [0.00138313 0.00207469 0.00276625 0.00345781 0.00414938 0.00484094\n 0.0055325  0.00622407 0.00691563 0.00760719 0.00829876 0.00899032\n 0.0093361  0.01037344 0.01106501 0.01141079 0.01210235 0.01279391\n 0.01348548 0.01417704 0.0148686  0.01556017 0.01625173 0.01694329\n 0.01763485 0.01832642 0.01901798 0.01970954 0.02040111 0.02109267\n 0.02178423 0.0224758  0.02316736 0.02385892 0.02455048 0.02524205\n 0.02558783 0.02662517 0.02697095 0.02766252 0.02869986 0.02904564\n 0.02973721 0.03042877 0.03112033 0.03181189 0.03250346 0.03319502\n 0.03388658 0.03457815 0.03526971 0.03596127 0.03665284 0.0373444\n 0.03803596 0.03872752 0.03941909 0.04011065 0.04080221 0.04149378\n 0.04218534 0.0428769  0.04356846 0.04426003 0.04495159 0.04564315\n 0.04633472 0.04702628 0.04771784 0.04840941 0.04910097 0.04979253\n 0.05048409 0.05117566 0.05186722 0.05255878 0.05325035 0.05394191\n 0.05463347 0.05532503 0.0560166  0.05670816 0.05739972 0.05809129\n 0.05878285 0.05947441 0.06016598 0.06085754 0.0615491  0.06224066\n 0.06293223 0.06362379 0.06431535 0.06500692 0.06569848 0.06639004\n 0.0670816  0.06777317 0.06846473 0.06915629 0.06984786 0.07053942\n 0.07123098 0.07192254 0.07261411 0.07330567 0.07399723 0.0746888\n 0.07538036 0.07607192 0.07676349 0.07745505 0.07814661 0.07883817\n 0.07987552 0.0802213  0.08125864 0.08160443 0.08229599 0.08264177\n 0.08333333 0.0840249  0.08471646 0.08540802 0.08609959 0.08679115\n 0.08748271 0.08817427 0.08886584 0.0895574  0.09024896 0.09059474\n 0.09094053 0.09163209 0.09232365 0.09301521 0.09370678 0.09439834\n 0.0950899  0.09578147 0.09647303 0.09751037 0.09785615 0.0988935\n 0.09958506 0.09993084 0.10096819 0.10165975 0.10235131 0.10304288\n 0.10373444 0.104426   0.10511757 0.10580913 0.10650069 0.10719225\n 0.10788382 0.10857538 0.10926694 0.11030429 0.11065007 0.11168741\n 0.11237898 0.11272476 0.1137621  0.11445367 0.11514523 0.11583679\n 0.11652835 0.11721992 0.11791148 0.11860304 0.11964039 0.11998617\n 0.12102351 0.12171508 0.12240664 0.1230982  0.12378976 0.12448133\n 0.12517289 0.12586445 0.12655602 0.12759336 0.12793914 0.12897649\n 0.12966805 0.13035961 0.13105118 0.13174274 0.1324343  0.13312586\n 0.13381743 0.13450899 0.13554633 0.1362379  0.13692946 0.13762102\n 0.13831259 0.13900415 0.13969571 0.14038728 0.14107884 0.1417704\n 0.14280775 0.14349931 0.14419087 0.14488243 0.145574   0.14626556\n 0.14695712 0.14764869 0.14868603 0.14903181 0.15006916 0.15076072\n 0.15145228 0.15214385 0.15283541 0.15352697 0.15421853 0.1549101\n 0.15594744 0.156639   0.15733057 0.15802213 0.15871369 0.15940526\n 0.16009682 0.16113416 0.16182573 0.16251729 0.16320885 0.16390041\n 0.16459198 0.16528354 0.16632089 0.16701245 0.16770401 0.16839557\n 0.16908714 0.1697787  0.17047026 0.17116183 0.17219917 0.17289073\n 0.1735823  0.17427386 0.17496542 0.17565698 0.17669433 0.17738589\n 0.17807746 0.17876902 0.17946058 0.18015214 0.1846473  0.18568465\n 0.1884509  0.18914246 0.19605809 0.20124481 0.20504841 0.21196404\n 0.21887967 0.24757953 0.29840941 0.32261411 0.34163209 0.36825726\n 0.39211618 0.41182573 0.44156293 0.47268326 0.47994467 0.49723375\n 0.51106501 0.52385892 0.52489627 0.55394191 0.55843707 0.58748271\n 0.5988935  0.6137621  0.63416321 0.64211618 0.65836791 0.66735823\n 0.67116183 0.67219917 0.69502075 0.71542185 0.71749654 0.73858921\n 0.74481328 0.75103734 0.78526971 0.80152144 0.81051176 0.84024896\n 0.87828492 0.88070539 0.90698479 0.92427386 0.9253112  0.9384509\n 0.94640387 0.94986169 0.95677732 0.9664592  0.97233748 1.        ]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317], got [0.         0.00138313 0.00207469 0.00276625 0.00345781 0.00414938\n 0.00484094 0.0055325  0.00622407 0.00691563 0.00760719 0.00829876\n 0.00899032 0.0093361  0.01037344 0.01106501 0.01141079 0.01210235\n 0.01279391 0.01348548 0.01417704 0.0148686  0.01556017 0.01625173\n 0.01694329 0.01763485 0.01832642 0.01901798 0.01970954 0.02040111\n 0.02109267 0.02178423 0.0224758  0.02316736 0.02385892 0.02455048\n 0.02524205 0.02558783 0.02662517 0.02697095 0.02766252 0.02869986\n 0.02904564 0.02973721 0.03042877 0.03112033 0.03181189 0.03250346\n 0.03319502 0.03388658 0.03457815 0.03526971 0.03596127 0.03665284\n 0.0373444  0.03803596 0.03872752 0.03941909 0.04011065 0.04080221\n 0.04149378 0.04218534 0.0428769  0.04356846 0.04426003 0.04495159\n 0.04564315 0.04633472 0.04702628 0.04771784 0.04840941 0.04910097\n 0.04979253 0.05048409 0.05117566 0.05186722 0.05255878 0.05325035\n 0.05394191 0.05463347 0.05532503 0.0560166  0.05670816 0.05739972\n 0.05809129 0.05878285 0.05947441 0.06016598 0.06085754 0.0615491\n 0.06224066 0.06293223 0.06362379 0.06431535 0.06500692 0.06569848\n 0.06639004 0.0670816  0.06777317 0.06846473 0.06915629 0.06984786\n 0.07053942 0.07123098 0.07192254 0.07261411 0.07330567 0.07399723\n 0.0746888  0.07538036 0.07607192 0.07676349 0.07745505 0.07814661\n 0.07883817 0.07987552 0.0802213  0.08125864 0.08160443 0.08229599\n 0.08264177 0.08333333 0.0840249  0.08471646 0.08540802 0.08609959\n 0.08679115 0.08748271 0.08817427 0.08886584 0.0895574  0.09024896\n 0.09059474 0.09094053 0.09163209 0.09232365 0.09301521 0.09370678\n 0.09439834 0.0950899  0.09578147 0.09647303 0.09751037 0.09785615\n 0.0988935  0.09958506 0.09993084 0.10096819 0.10165975 0.10235131\n 0.10304288 0.10373444 0.104426   0.10511757 0.10580913 0.10650069\n 0.10719225 0.10788382 0.10857538 0.10926694 0.11030429 0.11065007\n 0.11168741 0.11237898 0.11272476 0.1137621  0.11445367 0.11514523\n 0.11583679 0.11652835 0.11721992 0.11791148 0.11860304 0.11964039\n 0.11998617 0.12102351 0.12171508 0.12240664 0.1230982  0.12378976\n 0.12448133 0.12517289 0.12586445 0.12655602 0.12759336 0.12793914\n 0.12897649 0.12966805 0.13035961 0.13105118 0.13174274 0.1324343\n 0.13312586 0.13381743 0.13450899 0.13554633 0.1362379  0.13692946\n 0.13762102 0.13831259 0.13900415 0.13969571 0.14038728 0.14107884\n 0.1417704  0.14280775 0.14349931 0.14419087 0.14488243 0.145574\n 0.14626556 0.14695712 0.14764869 0.14868603 0.14903181 0.15006916\n 0.15076072 0.15145228 0.15214385 0.15283541 0.15352697 0.15421853\n 0.1549101  0.15594744 0.156639   0.15733057 0.15802213 0.15871369\n 0.15940526 0.16009682 0.16113416 0.16182573 0.16251729 0.16320885\n 0.16390041 0.16459198 0.16528354 0.16632089 0.16701245 0.16770401\n 0.16839557 0.16908714 0.1697787  0.17047026 0.17116183 0.17219917\n 0.17289073 0.1735823  0.17565698 0.17669433 0.17738589 0.17807746\n 0.17876902 0.17946058 0.18015214 0.18395574 0.1846473  0.18568465\n 0.18637621 0.1884509  0.18914246 0.19605809 0.20124481 0.20366528\n 0.20504841 0.21196404 0.25311203 0.29253112 0.29840941 0.32261411\n 0.34232365 0.39211618 0.41182573 0.41251729 0.4291148  0.46473029\n 0.47268326 0.47994467 0.48720609 0.48962656 0.51106501 0.52385892\n 0.55394191 0.58748271 0.5988935  0.61272476 0.6137621  0.61964039\n 0.63416321 0.64211618 0.65836791 0.66735823 0.67116183 0.67219917\n 0.71542185 0.71749654 0.74481328 0.75103734 0.75207469 0.75622407\n 0.78526971 0.80152144 0.81051176 0.84024896 0.88070539 0.90698479\n 0.9253112  0.93257261 0.9384509  0.94640387 0.94986169 0.95470263\n 0.95677732 0.9664592  0.96991701 0.97233748 0.97614108 1.        ]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317 318 319], got [0.         0.00138313 0.00207469 0.00276625 0.00345781 0.00414938\n 0.00484094 0.0055325  0.00622407 0.00691563 0.00760719 0.00829876\n 0.00899032 0.0093361  0.01037344 0.01106501 0.01141079 0.01210235\n 0.01279391 0.01348548 0.01417704 0.0148686  0.01556017 0.01625173\n 0.01694329 0.01763485 0.01832642 0.01901798 0.01970954 0.02040111\n 0.02109267 0.02178423 0.0224758  0.02316736 0.02385892 0.02455048\n 0.02524205 0.02558783 0.02662517 0.02697095 0.02766252 0.02869986\n 0.02904564 0.02973721 0.03042877 0.03112033 0.03181189 0.03250346\n 0.03319502 0.03388658 0.03457815 0.03526971 0.03596127 0.03665284\n 0.0373444  0.03803596 0.03872752 0.03941909 0.04011065 0.04080221\n 0.04149378 0.04218534 0.0428769  0.04356846 0.04426003 0.04495159\n 0.04564315 0.04633472 0.04702628 0.04771784 0.04840941 0.04910097\n 0.04979253 0.05048409 0.05117566 0.05186722 0.05255878 0.05325035\n 0.05394191 0.05463347 0.05532503 0.0560166  0.05670816 0.05739972\n 0.05809129 0.05878285 0.05947441 0.06016598 0.06085754 0.0615491\n 0.06224066 0.06293223 0.06362379 0.06431535 0.06500692 0.06569848\n 0.06639004 0.0670816  0.06777317 0.06846473 0.06915629 0.06984786\n 0.07053942 0.07123098 0.07192254 0.07261411 0.07330567 0.07399723\n 0.0746888  0.07538036 0.07607192 0.07676349 0.07745505 0.07814661\n 0.07883817 0.07987552 0.0802213  0.08125864 0.08160443 0.08229599\n 0.08264177 0.08333333 0.0840249  0.08471646 0.08540802 0.08609959\n 0.08679115 0.08748271 0.08817427 0.08886584 0.0895574  0.09024896\n 0.09059474 0.09094053 0.09163209 0.09232365 0.09301521 0.09370678\n 0.09439834 0.0950899  0.09578147 0.09647303 0.09751037 0.09785615\n 0.0988935  0.09958506 0.09993084 0.10096819 0.10165975 0.10235131\n 0.10304288 0.10373444 0.104426   0.10511757 0.10580913 0.10650069\n 0.10719225 0.10788382 0.10857538 0.10926694 0.11030429 0.11065007\n 0.11168741 0.11237898 0.11272476 0.1137621  0.11445367 0.11514523\n 0.11583679 0.11652835 0.11721992 0.11791148 0.11860304 0.11964039\n 0.11998617 0.12102351 0.12171508 0.12240664 0.1230982  0.12378976\n 0.12448133 0.12517289 0.12586445 0.12655602 0.12759336 0.12793914\n 0.12897649 0.12966805 0.13035961 0.13105118 0.13174274 0.1324343\n 0.13312586 0.13381743 0.13450899 0.13554633 0.1362379  0.13692946\n 0.13762102 0.13831259 0.13900415 0.13969571 0.14038728 0.14107884\n 0.1417704  0.14280775 0.14349931 0.14419087 0.14488243 0.145574\n 0.14626556 0.14695712 0.14764869 0.14868603 0.14903181 0.15006916\n 0.15076072 0.15145228 0.15214385 0.15283541 0.15352697 0.15421853\n 0.1549101  0.15594744 0.156639   0.15733057 0.15802213 0.15871369\n 0.15940526 0.16009682 0.16113416 0.16182573 0.16251729 0.16320885\n 0.16390041 0.16459198 0.16528354 0.16632089 0.16770401 0.16839557\n 0.16908714 0.1697787  0.17047026 0.17116183 0.17219917 0.1735823\n 0.17427386 0.17496542 0.17565698 0.17669433 0.17738589 0.17807746\n 0.17876902 0.17946058 0.18015214 0.18395574 0.1846473  0.18568465\n 0.18637621 0.1884509  0.18914246 0.20124481 0.20366528 0.20504841\n 0.21887967 0.24757953 0.25311203 0.29253112 0.29840941 0.34163209\n 0.34232365 0.36825726 0.41182573 0.41251729 0.4291148  0.44156293\n 0.46473029 0.47268326 0.48720609 0.48962656 0.49723375 0.51106501\n 0.52385892 0.52489627 0.55394191 0.55843707 0.58748271 0.5988935\n 0.61272476 0.61964039 0.64211618 0.65836791 0.67116183 0.67219917\n 0.69502075 0.71542185 0.71749654 0.73858921 0.74481328 0.75103734\n 0.75207469 0.75622407 0.78526971 0.81051176 0.84024896 0.87828492\n 0.88070539 0.90698479 0.92427386 0.93257261 0.9384509  0.94640387\n 0.94986169 0.95470263 0.95677732 0.9664592  0.96991701 0.97233748\n 0.97614108 1.        ]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317 318], got [0.         0.00138313 0.00207469 0.00276625 0.00345781 0.00414938\n 0.00484094 0.0055325  0.00622407 0.00691563 0.00760719 0.00829876\n 0.00899032 0.0093361  0.01037344 0.01106501 0.01141079 0.01210235\n 0.01279391 0.01348548 0.01417704 0.0148686  0.01556017 0.01625173\n 0.01694329 0.01763485 0.01832642 0.01901798 0.01970954 0.02040111\n 0.02109267 0.02178423 0.0224758  0.02316736 0.02385892 0.02455048\n 0.02524205 0.02558783 0.02662517 0.02697095 0.02766252 0.02869986\n 0.02904564 0.02973721 0.03042877 0.03112033 0.03181189 0.03250346\n 0.03319502 0.03388658 0.03457815 0.03526971 0.03596127 0.03665284\n 0.0373444  0.03803596 0.03872752 0.03941909 0.04011065 0.04080221\n 0.04149378 0.04218534 0.0428769  0.04356846 0.04426003 0.04495159\n 0.04564315 0.04633472 0.04702628 0.04771784 0.04840941 0.04910097\n 0.04979253 0.05048409 0.05117566 0.05186722 0.05255878 0.05325035\n 0.05394191 0.05463347 0.05532503 0.0560166  0.05670816 0.05739972\n 0.05809129 0.05878285 0.05947441 0.06016598 0.06085754 0.0615491\n 0.06224066 0.06293223 0.06362379 0.06431535 0.06500692 0.06569848\n 0.06639004 0.0670816  0.06777317 0.06846473 0.06915629 0.06984786\n 0.07053942 0.07123098 0.07192254 0.07261411 0.07330567 0.07399723\n 0.0746888  0.07538036 0.07607192 0.07676349 0.07745505 0.07814661\n 0.07883817 0.07987552 0.0802213  0.08125864 0.08160443 0.08229599\n 0.08264177 0.08333333 0.0840249  0.08471646 0.08540802 0.08609959\n 0.08679115 0.08748271 0.08817427 0.08886584 0.0895574  0.09024896\n 0.09059474 0.09094053 0.09163209 0.09232365 0.09301521 0.09370678\n 0.09439834 0.0950899  0.09578147 0.09647303 0.09751037 0.09785615\n 0.0988935  0.09958506 0.09993084 0.10096819 0.10165975 0.10235131\n 0.10304288 0.10373444 0.104426   0.10511757 0.10580913 0.10650069\n 0.10719225 0.10788382 0.10857538 0.10926694 0.11030429 0.11065007\n 0.11168741 0.11237898 0.11272476 0.1137621  0.11445367 0.11514523\n 0.11583679 0.11652835 0.11721992 0.11791148 0.11860304 0.11964039\n 0.11998617 0.12102351 0.12171508 0.12240664 0.1230982  0.12378976\n 0.12448133 0.12517289 0.12586445 0.12655602 0.12759336 0.12793914\n 0.12897649 0.12966805 0.13035961 0.13105118 0.13174274 0.1324343\n 0.13312586 0.13381743 0.13450899 0.13554633 0.1362379  0.13692946\n 0.13762102 0.13831259 0.13900415 0.13969571 0.14038728 0.14107884\n 0.1417704  0.14280775 0.14349931 0.14419087 0.14488243 0.145574\n 0.14626556 0.14695712 0.14764869 0.14868603 0.14903181 0.15006916\n 0.15076072 0.15145228 0.15214385 0.15283541 0.15352697 0.15421853\n 0.1549101  0.15594744 0.156639   0.15733057 0.15802213 0.15871369\n 0.15940526 0.16009682 0.16113416 0.16182573 0.16251729 0.16320885\n 0.16390041 0.16459198 0.16528354 0.16632089 0.16701245 0.16770401\n 0.16839557 0.16908714 0.17047026 0.17116183 0.17219917 0.17289073\n 0.1735823  0.17427386 0.17496542 0.17565698 0.17669433 0.17738589\n 0.17807746 0.17876902 0.17946058 0.18015214 0.18395574 0.1846473\n 0.18637621 0.1884509  0.18914246 0.19605809 0.20124481 0.20366528\n 0.20504841 0.21196404 0.21887967 0.24757953 0.25311203 0.29253112\n 0.29840941 0.32261411 0.34163209 0.34232365 0.36825726 0.39211618\n 0.41182573 0.41251729 0.4291148  0.44156293 0.46473029 0.47994467\n 0.48720609 0.48962656 0.49723375 0.52385892 0.52489627 0.55394191\n 0.55843707 0.5988935  0.61272476 0.6137621  0.61964039 0.63416321\n 0.64211618 0.65836791 0.66735823 0.69502075 0.71542185 0.73858921\n 0.74481328 0.75207469 0.75622407 0.80152144 0.81051176 0.87828492\n 0.88070539 0.92427386 0.9253112  0.93257261 0.9384509  0.94640387\n 0.94986169 0.95470263 0.95677732 0.9664592  0.96991701 0.97614108\n 1.        ]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier(objective\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mreg:squarederror\u001b[39m\u001b[39m'\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m) \u001b[39m# Adjust hyperparameters as needed\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# Perform cross-validation and calculate mean score\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m cv_scores \u001b[39m=\u001b[39m cross_val_score(model, X_train[\u001b[39mlist\u001b[39;49m(combo)], y_train, cv\u001b[39m=\u001b[39;49mcv_folds, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mr2\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     36\u001b[0m mean_cv_score \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(cv_scores)\n\u001b[1;32m     38\u001b[0m \u001b[39m# Store the mean cross-validation score in a dictionary\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    527\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m    266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[0;32m--> 285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316], got [0.         0.00138313 0.00207469 0.00276625 0.00345781 0.00414938\n 0.00484094 0.0055325  0.00622407 0.00691563 0.00760719 0.00829876\n 0.00899032 0.0093361  0.01037344 0.01106501 0.01141079 0.01210235\n 0.01279391 0.01348548 0.01417704 0.0148686  0.01556017 0.01625173\n 0.01694329 0.01763485 0.01832642 0.01901798 0.01970954 0.02040111\n 0.02109267 0.02178423 0.0224758  0.02316736 0.02385892 0.02455048\n 0.02524205 0.02558783 0.02662517 0.02697095 0.02766252 0.02869986\n 0.02904564 0.02973721 0.03042877 0.03112033 0.03181189 0.03250346\n 0.03319502 0.03388658 0.03457815 0.03526971 0.03596127 0.03665284\n 0.0373444  0.03803596 0.03872752 0.03941909 0.04011065 0.04080221\n 0.04149378 0.04218534 0.0428769  0.04356846 0.04426003 0.04495159\n 0.04564315 0.04633472 0.04702628 0.04771784 0.04840941 0.04910097\n 0.04979253 0.05048409 0.05117566 0.05186722 0.05255878 0.05325035\n 0.05394191 0.05463347 0.05532503 0.0560166  0.05670816 0.05739972\n 0.05809129 0.05878285 0.05947441 0.06016598 0.06085754 0.0615491\n 0.06224066 0.06293223 0.06362379 0.06431535 0.06500692 0.06569848\n 0.06639004 0.0670816  0.06777317 0.06846473 0.06915629 0.06984786\n 0.07053942 0.07123098 0.07192254 0.07261411 0.07330567 0.07399723\n 0.0746888  0.07538036 0.07607192 0.07676349 0.07745505 0.07814661\n 0.07883817 0.07987552 0.0802213  0.08125864 0.08160443 0.08264177\n 0.08333333 0.0840249  0.08471646 0.08540802 0.08609959 0.08679115\n 0.08748271 0.08817427 0.08886584 0.0895574  0.09024896 0.09094053\n 0.09163209 0.09232365 0.09301521 0.09370678 0.09439834 0.0950899\n 0.09578147 0.09647303 0.09751037 0.09785615 0.0988935  0.09958506\n 0.09993084 0.10096819 0.10165975 0.10235131 0.10304288 0.10373444\n 0.104426   0.10511757 0.10580913 0.10650069 0.10719225 0.10788382\n 0.10857538 0.10926694 0.11030429 0.11065007 0.11168741 0.11237898\n 0.11272476 0.1137621  0.11445367 0.11514523 0.11583679 0.11652835\n 0.11721992 0.11791148 0.11860304 0.11964039 0.11998617 0.12102351\n 0.12171508 0.12240664 0.1230982  0.12378976 0.12448133 0.12517289\n 0.12586445 0.12655602 0.12759336 0.12793914 0.12897649 0.12966805\n 0.13035961 0.13105118 0.13174274 0.1324343  0.13312586 0.13381743\n 0.13450899 0.13554633 0.1362379  0.13692946 0.13762102 0.13831259\n 0.13900415 0.13969571 0.14038728 0.14107884 0.1417704  0.14280775\n 0.14349931 0.14419087 0.14488243 0.145574   0.14626556 0.14695712\n 0.14764869 0.14868603 0.14903181 0.15006916 0.15076072 0.15145228\n 0.15214385 0.15283541 0.15352697 0.15421853 0.1549101  0.15594744\n 0.156639   0.15733057 0.15802213 0.15871369 0.15940526 0.16009682\n 0.16113416 0.16182573 0.16251729 0.16320885 0.16390041 0.16459198\n 0.16528354 0.16632089 0.16701245 0.16770401 0.16839557 0.16908714\n 0.1697787  0.17047026 0.17116183 0.17219917 0.17289073 0.1735823\n 0.17427386 0.17496542 0.17565698 0.17669433 0.17738589 0.17807746\n 0.17876902 0.17946058 0.18015214 0.18395574 0.1846473  0.18568465\n 0.18637621 0.1884509  0.18914246 0.19605809 0.20366528 0.21196404\n 0.21887967 0.24757953 0.25311203 0.29253112 0.32261411 0.34163209\n 0.34232365 0.36825726 0.39211618 0.41251729 0.4291148  0.44156293\n 0.46473029 0.47268326 0.47994467 0.48720609 0.48962656 0.49723375\n 0.51106501 0.52489627 0.55843707 0.58748271 0.61272476 0.6137621\n 0.61964039 0.63416321 0.64211618 0.66735823 0.67116183 0.67219917\n 0.69502075 0.71749654 0.73858921 0.75103734 0.75207469 0.75622407\n 0.78526971 0.80152144 0.81051176 0.84024896 0.87828492 0.88070539\n 0.90698479 0.92427386 0.9253112  0.93257261 0.94640387 0.95470263\n 0.9664592  0.96991701 0.97233748 0.97614108 1.        ]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311], got [0.00138313 0.00207469 0.00276625 0.00345781 0.00414938 0.00484094\n 0.0055325  0.00622407 0.00691563 0.00760719 0.00829876 0.00899032\n 0.0093361  0.01037344 0.01106501 0.01141079 0.01210235 0.01279391\n 0.01348548 0.01417704 0.0148686  0.01556017 0.01625173 0.01694329\n 0.01763485 0.01832642 0.01901798 0.01970954 0.02040111 0.02109267\n 0.02178423 0.0224758  0.02316736 0.02385892 0.02455048 0.02524205\n 0.02558783 0.02662517 0.02697095 0.02766252 0.02869986 0.02904564\n 0.02973721 0.03042877 0.03112033 0.03181189 0.03250346 0.03319502\n 0.03388658 0.03457815 0.03526971 0.03596127 0.03665284 0.0373444\n 0.03803596 0.03872752 0.03941909 0.04011065 0.04080221 0.04149378\n 0.04218534 0.0428769  0.04356846 0.04426003 0.04495159 0.04564315\n 0.04633472 0.04702628 0.04771784 0.04840941 0.04910097 0.04979253\n 0.05048409 0.05117566 0.05186722 0.05255878 0.05325035 0.05394191\n 0.05463347 0.05532503 0.0560166  0.05670816 0.05739972 0.05809129\n 0.05878285 0.05947441 0.06016598 0.06085754 0.0615491  0.06224066\n 0.06293223 0.06362379 0.06431535 0.06500692 0.06569848 0.06639004\n 0.0670816  0.06777317 0.06846473 0.06915629 0.06984786 0.07053942\n 0.07123098 0.07192254 0.07261411 0.07330567 0.07399723 0.0746888\n 0.07538036 0.07607192 0.07676349 0.07745505 0.07814661 0.07883817\n 0.07987552 0.0802213  0.08125864 0.08160443 0.08229599 0.08264177\n 0.08333333 0.0840249  0.08471646 0.08540802 0.08609959 0.08679115\n 0.08748271 0.08817427 0.08886584 0.0895574  0.09024896 0.09059474\n 0.09094053 0.09163209 0.09232365 0.09301521 0.09370678 0.09439834\n 0.0950899  0.09578147 0.09647303 0.09751037 0.09785615 0.0988935\n 0.09958506 0.09993084 0.10096819 0.10165975 0.10235131 0.10304288\n 0.10373444 0.104426   0.10511757 0.10580913 0.10650069 0.10719225\n 0.10788382 0.10857538 0.10926694 0.11030429 0.11065007 0.11168741\n 0.11237898 0.11272476 0.1137621  0.11445367 0.11514523 0.11583679\n 0.11652835 0.11721992 0.11791148 0.11860304 0.11964039 0.11998617\n 0.12102351 0.12171508 0.12240664 0.1230982  0.12378976 0.12448133\n 0.12517289 0.12586445 0.12655602 0.12759336 0.12793914 0.12897649\n 0.12966805 0.13035961 0.13105118 0.13174274 0.1324343  0.13312586\n 0.13381743 0.13450899 0.13554633 0.1362379  0.13692946 0.13762102\n 0.13831259 0.13900415 0.13969571 0.14038728 0.14107884 0.1417704\n 0.14280775 0.14349931 0.14419087 0.14488243 0.145574   0.14626556\n 0.14695712 0.14764869 0.14868603 0.14903181 0.15006916 0.15076072\n 0.15145228 0.15214385 0.15283541 0.15352697 0.15421853 0.1549101\n 0.15594744 0.156639   0.15733057 0.15802213 0.15871369 0.15940526\n 0.16009682 0.16113416 0.16182573 0.16251729 0.16320885 0.16390041\n 0.16459198 0.16528354 0.16632089 0.16701245 0.16770401 0.16839557\n 0.16908714 0.1697787  0.17047026 0.17116183 0.17219917 0.17289073\n 0.1735823  0.17427386 0.17496542 0.17565698 0.17669433 0.17738589\n 0.17807746 0.17876902 0.17946058 0.18015214 0.1846473  0.18568465\n 0.1884509  0.18914246 0.19605809 0.20124481 0.20504841 0.21196404\n 0.21887967 0.24757953 0.29840941 0.32261411 0.34163209 0.36825726\n 0.39211618 0.41182573 0.44156293 0.47268326 0.47994467 0.49723375\n 0.51106501 0.52385892 0.52489627 0.55394191 0.55843707 0.58748271\n 0.5988935  0.6137621  0.63416321 0.64211618 0.65836791 0.66735823\n 0.67116183 0.67219917 0.69502075 0.71542185 0.71749654 0.73858921\n 0.74481328 0.75103734 0.78526971 0.80152144 0.81051176 0.84024896\n 0.87828492 0.88070539 0.90698479 0.92427386 0.9253112  0.9384509\n 0.94640387 0.94986169 0.95677732 0.9664592  0.97233748 1.        ]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317], got [0.         0.00138313 0.00207469 0.00276625 0.00345781 0.00414938\n 0.00484094 0.0055325  0.00622407 0.00691563 0.00760719 0.00829876\n 0.00899032 0.0093361  0.01037344 0.01106501 0.01141079 0.01210235\n 0.01279391 0.01348548 0.01417704 0.0148686  0.01556017 0.01625173\n 0.01694329 0.01763485 0.01832642 0.01901798 0.01970954 0.02040111\n 0.02109267 0.02178423 0.0224758  0.02316736 0.02385892 0.02455048\n 0.02524205 0.02558783 0.02662517 0.02697095 0.02766252 0.02869986\n 0.02904564 0.02973721 0.03042877 0.03112033 0.03181189 0.03250346\n 0.03319502 0.03388658 0.03457815 0.03526971 0.03596127 0.03665284\n 0.0373444  0.03803596 0.03872752 0.03941909 0.04011065 0.04080221\n 0.04149378 0.04218534 0.0428769  0.04356846 0.04426003 0.04495159\n 0.04564315 0.04633472 0.04702628 0.04771784 0.04840941 0.04910097\n 0.04979253 0.05048409 0.05117566 0.05186722 0.05255878 0.05325035\n 0.05394191 0.05463347 0.05532503 0.0560166  0.05670816 0.05739972\n 0.05809129 0.05878285 0.05947441 0.06016598 0.06085754 0.0615491\n 0.06224066 0.06293223 0.06362379 0.06431535 0.06500692 0.06569848\n 0.06639004 0.0670816  0.06777317 0.06846473 0.06915629 0.06984786\n 0.07053942 0.07123098 0.07192254 0.07261411 0.07330567 0.07399723\n 0.0746888  0.07538036 0.07607192 0.07676349 0.07745505 0.07814661\n 0.07883817 0.07987552 0.0802213  0.08125864 0.08160443 0.08229599\n 0.08264177 0.08333333 0.0840249  0.08471646 0.08540802 0.08609959\n 0.08679115 0.08748271 0.08817427 0.08886584 0.0895574  0.09024896\n 0.09059474 0.09094053 0.09163209 0.09232365 0.09301521 0.09370678\n 0.09439834 0.0950899  0.09578147 0.09647303 0.09751037 0.09785615\n 0.0988935  0.09958506 0.09993084 0.10096819 0.10165975 0.10235131\n 0.10304288 0.10373444 0.104426   0.10511757 0.10580913 0.10650069\n 0.10719225 0.10788382 0.10857538 0.10926694 0.11030429 0.11065007\n 0.11168741 0.11237898 0.11272476 0.1137621  0.11445367 0.11514523\n 0.11583679 0.11652835 0.11721992 0.11791148 0.11860304 0.11964039\n 0.11998617 0.12102351 0.12171508 0.12240664 0.1230982  0.12378976\n 0.12448133 0.12517289 0.12586445 0.12655602 0.12759336 0.12793914\n 0.12897649 0.12966805 0.13035961 0.13105118 0.13174274 0.1324343\n 0.13312586 0.13381743 0.13450899 0.13554633 0.1362379  0.13692946\n 0.13762102 0.13831259 0.13900415 0.13969571 0.14038728 0.14107884\n 0.1417704  0.14280775 0.14349931 0.14419087 0.14488243 0.145574\n 0.14626556 0.14695712 0.14764869 0.14868603 0.14903181 0.15006916\n 0.15076072 0.15145228 0.15214385 0.15283541 0.15352697 0.15421853\n 0.1549101  0.15594744 0.156639   0.15733057 0.15802213 0.15871369\n 0.15940526 0.16009682 0.16113416 0.16182573 0.16251729 0.16320885\n 0.16390041 0.16459198 0.16528354 0.16632089 0.16701245 0.16770401\n 0.16839557 0.16908714 0.1697787  0.17047026 0.17116183 0.17219917\n 0.17289073 0.1735823  0.17565698 0.17669433 0.17738589 0.17807746\n 0.17876902 0.17946058 0.18015214 0.18395574 0.1846473  0.18568465\n 0.18637621 0.1884509  0.18914246 0.19605809 0.20124481 0.20366528\n 0.20504841 0.21196404 0.25311203 0.29253112 0.29840941 0.32261411\n 0.34232365 0.39211618 0.41182573 0.41251729 0.4291148  0.46473029\n 0.47268326 0.47994467 0.48720609 0.48962656 0.51106501 0.52385892\n 0.55394191 0.58748271 0.5988935  0.61272476 0.6137621  0.61964039\n 0.63416321 0.64211618 0.65836791 0.66735823 0.67116183 0.67219917\n 0.71542185 0.71749654 0.74481328 0.75103734 0.75207469 0.75622407\n 0.78526971 0.80152144 0.81051176 0.84024896 0.88070539 0.90698479\n 0.9253112  0.93257261 0.9384509  0.94640387 0.94986169 0.95470263\n 0.95677732 0.9664592  0.96991701 0.97233748 0.97614108 1.        ]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317 318 319], got [0.         0.00138313 0.00207469 0.00276625 0.00345781 0.00414938\n 0.00484094 0.0055325  0.00622407 0.00691563 0.00760719 0.00829876\n 0.00899032 0.0093361  0.01037344 0.01106501 0.01141079 0.01210235\n 0.01279391 0.01348548 0.01417704 0.0148686  0.01556017 0.01625173\n 0.01694329 0.01763485 0.01832642 0.01901798 0.01970954 0.02040111\n 0.02109267 0.02178423 0.0224758  0.02316736 0.02385892 0.02455048\n 0.02524205 0.02558783 0.02662517 0.02697095 0.02766252 0.02869986\n 0.02904564 0.02973721 0.03042877 0.03112033 0.03181189 0.03250346\n 0.03319502 0.03388658 0.03457815 0.03526971 0.03596127 0.03665284\n 0.0373444  0.03803596 0.03872752 0.03941909 0.04011065 0.04080221\n 0.04149378 0.04218534 0.0428769  0.04356846 0.04426003 0.04495159\n 0.04564315 0.04633472 0.04702628 0.04771784 0.04840941 0.04910097\n 0.04979253 0.05048409 0.05117566 0.05186722 0.05255878 0.05325035\n 0.05394191 0.05463347 0.05532503 0.0560166  0.05670816 0.05739972\n 0.05809129 0.05878285 0.05947441 0.06016598 0.06085754 0.0615491\n 0.06224066 0.06293223 0.06362379 0.06431535 0.06500692 0.06569848\n 0.06639004 0.0670816  0.06777317 0.06846473 0.06915629 0.06984786\n 0.07053942 0.07123098 0.07192254 0.07261411 0.07330567 0.07399723\n 0.0746888  0.07538036 0.07607192 0.07676349 0.07745505 0.07814661\n 0.07883817 0.07987552 0.0802213  0.08125864 0.08160443 0.08229599\n 0.08264177 0.08333333 0.0840249  0.08471646 0.08540802 0.08609959\n 0.08679115 0.08748271 0.08817427 0.08886584 0.0895574  0.09024896\n 0.09059474 0.09094053 0.09163209 0.09232365 0.09301521 0.09370678\n 0.09439834 0.0950899  0.09578147 0.09647303 0.09751037 0.09785615\n 0.0988935  0.09958506 0.09993084 0.10096819 0.10165975 0.10235131\n 0.10304288 0.10373444 0.104426   0.10511757 0.10580913 0.10650069\n 0.10719225 0.10788382 0.10857538 0.10926694 0.11030429 0.11065007\n 0.11168741 0.11237898 0.11272476 0.1137621  0.11445367 0.11514523\n 0.11583679 0.11652835 0.11721992 0.11791148 0.11860304 0.11964039\n 0.11998617 0.12102351 0.12171508 0.12240664 0.1230982  0.12378976\n 0.12448133 0.12517289 0.12586445 0.12655602 0.12759336 0.12793914\n 0.12897649 0.12966805 0.13035961 0.13105118 0.13174274 0.1324343\n 0.13312586 0.13381743 0.13450899 0.13554633 0.1362379  0.13692946\n 0.13762102 0.13831259 0.13900415 0.13969571 0.14038728 0.14107884\n 0.1417704  0.14280775 0.14349931 0.14419087 0.14488243 0.145574\n 0.14626556 0.14695712 0.14764869 0.14868603 0.14903181 0.15006916\n 0.15076072 0.15145228 0.15214385 0.15283541 0.15352697 0.15421853\n 0.1549101  0.15594744 0.156639   0.15733057 0.15802213 0.15871369\n 0.15940526 0.16009682 0.16113416 0.16182573 0.16251729 0.16320885\n 0.16390041 0.16459198 0.16528354 0.16632089 0.16770401 0.16839557\n 0.16908714 0.1697787  0.17047026 0.17116183 0.17219917 0.1735823\n 0.17427386 0.17496542 0.17565698 0.17669433 0.17738589 0.17807746\n 0.17876902 0.17946058 0.18015214 0.18395574 0.1846473  0.18568465\n 0.18637621 0.1884509  0.18914246 0.20124481 0.20366528 0.20504841\n 0.21887967 0.24757953 0.25311203 0.29253112 0.29840941 0.34163209\n 0.34232365 0.36825726 0.41182573 0.41251729 0.4291148  0.44156293\n 0.46473029 0.47268326 0.48720609 0.48962656 0.49723375 0.51106501\n 0.52385892 0.52489627 0.55394191 0.55843707 0.58748271 0.5988935\n 0.61272476 0.61964039 0.64211618 0.65836791 0.67116183 0.67219917\n 0.69502075 0.71542185 0.71749654 0.73858921 0.74481328 0.75103734\n 0.75207469 0.75622407 0.78526971 0.81051176 0.84024896 0.87828492\n 0.88070539 0.90698479 0.92427386 0.93257261 0.9384509  0.94640387\n 0.94986169 0.95470263 0.95677732 0.9664592  0.96991701 0.97233748\n 0.97614108 1.        ]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"/opt/homebrew/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n 306 307 308 309 310 311 312 313 314 315 316 317 318], got [0.         0.00138313 0.00207469 0.00276625 0.00345781 0.00414938\n 0.00484094 0.0055325  0.00622407 0.00691563 0.00760719 0.00829876\n 0.00899032 0.0093361  0.01037344 0.01106501 0.01141079 0.01210235\n 0.01279391 0.01348548 0.01417704 0.0148686  0.01556017 0.01625173\n 0.01694329 0.01763485 0.01832642 0.01901798 0.01970954 0.02040111\n 0.02109267 0.02178423 0.0224758  0.02316736 0.02385892 0.02455048\n 0.02524205 0.02558783 0.02662517 0.02697095 0.02766252 0.02869986\n 0.02904564 0.02973721 0.03042877 0.03112033 0.03181189 0.03250346\n 0.03319502 0.03388658 0.03457815 0.03526971 0.03596127 0.03665284\n 0.0373444  0.03803596 0.03872752 0.03941909 0.04011065 0.04080221\n 0.04149378 0.04218534 0.0428769  0.04356846 0.04426003 0.04495159\n 0.04564315 0.04633472 0.04702628 0.04771784 0.04840941 0.04910097\n 0.04979253 0.05048409 0.05117566 0.05186722 0.05255878 0.05325035\n 0.05394191 0.05463347 0.05532503 0.0560166  0.05670816 0.05739972\n 0.05809129 0.05878285 0.05947441 0.06016598 0.06085754 0.0615491\n 0.06224066 0.06293223 0.06362379 0.06431535 0.06500692 0.06569848\n 0.06639004 0.0670816  0.06777317 0.06846473 0.06915629 0.06984786\n 0.07053942 0.07123098 0.07192254 0.07261411 0.07330567 0.07399723\n 0.0746888  0.07538036 0.07607192 0.07676349 0.07745505 0.07814661\n 0.07883817 0.07987552 0.0802213  0.08125864 0.08160443 0.08229599\n 0.08264177 0.08333333 0.0840249  0.08471646 0.08540802 0.08609959\n 0.08679115 0.08748271 0.08817427 0.08886584 0.0895574  0.09024896\n 0.09059474 0.09094053 0.09163209 0.09232365 0.09301521 0.09370678\n 0.09439834 0.0950899  0.09578147 0.09647303 0.09751037 0.09785615\n 0.0988935  0.09958506 0.09993084 0.10096819 0.10165975 0.10235131\n 0.10304288 0.10373444 0.104426   0.10511757 0.10580913 0.10650069\n 0.10719225 0.10788382 0.10857538 0.10926694 0.11030429 0.11065007\n 0.11168741 0.11237898 0.11272476 0.1137621  0.11445367 0.11514523\n 0.11583679 0.11652835 0.11721992 0.11791148 0.11860304 0.11964039\n 0.11998617 0.12102351 0.12171508 0.12240664 0.1230982  0.12378976\n 0.12448133 0.12517289 0.12586445 0.12655602 0.12759336 0.12793914\n 0.12897649 0.12966805 0.13035961 0.13105118 0.13174274 0.1324343\n 0.13312586 0.13381743 0.13450899 0.13554633 0.1362379  0.13692946\n 0.13762102 0.13831259 0.13900415 0.13969571 0.14038728 0.14107884\n 0.1417704  0.14280775 0.14349931 0.14419087 0.14488243 0.145574\n 0.14626556 0.14695712 0.14764869 0.14868603 0.14903181 0.15006916\n 0.15076072 0.15145228 0.15214385 0.15283541 0.15352697 0.15421853\n 0.1549101  0.15594744 0.156639   0.15733057 0.15802213 0.15871369\n 0.15940526 0.16009682 0.16113416 0.16182573 0.16251729 0.16320885\n 0.16390041 0.16459198 0.16528354 0.16632089 0.16701245 0.16770401\n 0.16839557 0.16908714 0.17047026 0.17116183 0.17219917 0.17289073\n 0.1735823  0.17427386 0.17496542 0.17565698 0.17669433 0.17738589\n 0.17807746 0.17876902 0.17946058 0.18015214 0.18395574 0.1846473\n 0.18637621 0.1884509  0.18914246 0.19605809 0.20124481 0.20366528\n 0.20504841 0.21196404 0.21887967 0.24757953 0.25311203 0.29253112\n 0.29840941 0.32261411 0.34163209 0.34232365 0.36825726 0.39211618\n 0.41182573 0.41251729 0.4291148  0.44156293 0.46473029 0.47994467\n 0.48720609 0.48962656 0.49723375 0.52385892 0.52489627 0.55394191\n 0.55843707 0.5988935  0.61272476 0.6137621  0.61964039 0.63416321\n 0.64211618 0.65836791 0.66735823 0.69502075 0.71542185 0.73858921\n 0.74481328 0.75207469 0.75622407 0.80152144 0.81051176 0.87828492\n 0.88070539 0.92427386 0.9253112  0.93257261 0.9384509  0.94640387\n 0.94986169 0.95470263 0.95677732 0.9664592  0.96991701 0.97614108\n 1.        ]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from itertools import chain, combinations\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Independent variables\n",
    "independent_vars = [\"temperature\", \"humidity\", \"pressure\", \"tvoc\"]\n",
    "\n",
    "# Function to get all combinations of the independent variables\n",
    "def all_combinations(variables):\n",
    "    return list(chain(*map(lambda x: combinations(variables, x), range(1, len(variables) + 1))))\n",
    "\n",
    "# Get all combinations of independent variables\n",
    "combinations = all_combinations(independent_vars)\n",
    "\n",
    "# Dependent variable\n",
    "dependent_var = \"radon\"\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[independent_vars], df[dependent_var], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a dictionary to store mean cross-validation scores\n",
    "mean_cv_scores = {}\n",
    "\n",
    "# Number of folds for cross-validation\n",
    "cv_folds = 5\n",
    "\n",
    "# Iterate over each combination of independent variables\n",
    "for combo in combinations:\n",
    "    # Train an XGBoost regression model\n",
    "    model = xgb.XGBClassifier(objective='reg:squarederror', random_state=42) # Adjust hyperparameters as needed\n",
    "    \n",
    "    # Perform cross-validation and calculate mean score\n",
    "    cv_scores = cross_val_score(model, X_train[list(combo)], y_train, cv=cv_folds, scoring='r2')\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    \n",
    "    # Store the mean cross-validation score in a dictionary\n",
    "    mean_cv_scores[combo] = mean_cv_score\n",
    "\n",
    "# Find the combination with the highest mean cross-validation score\n",
    "best_combo = max(mean_cv_scores, key=mean_cv_scores.get)\n",
    "\n",
    "print(\"Best combination of independent variables:\", best_combo)\n",
    "print(\"Highest mean cross-validation score:\", mean_cv_scores[best_combo])\n",
    "\n",
    "# Train the final model using the best combination of independent variables and the entire training set\n",
    "best_model = xgb.XGBClassifier(objective='reg:squarederror', random_state=42) # Adjust hyperparameters as needed\n",
    "best_model.fit(X_train[list(best_combo)], y_train)\n",
    "\n",
    "# Make predictions using the test set\n",
    "y_pred = best_model.predict(X_test[list(best_combo)])\n",
    "\n",
    "# Calculate R-squared score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"R-squared score on the test set:\", r2)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error on the test set:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees: Model Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination of independent variables: ('temperature', 'humidity', 'pressure', 'tvoc')\n",
      "Highest R-squared score: 0.6134782471496891\n",
      "Mean absolute error: 0.02014222705939061\n",
      "Mean squared error: 0.0009671201704714494\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from itertools import chain, combinations\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "\n",
    "# Independent variables\n",
    "independent_vars = [\"temperature\", \"humidity\", \"pressure\", \"tvoc\"]\n",
    "\n",
    "# Function to get all combinations of the independent variables\n",
    "def all_combinations(variables):\n",
    "    return list(chain(*map(lambda x: combinations(variables, x), range(1, len(variables) + 1))))\n",
    "\n",
    "# Get all combinations of independent variables\n",
    "combinations = all_combinations(independent_vars)\n",
    "\n",
    "# Dependent variable\n",
    "dependent_var = \"radon\"\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[independent_vars], df[dependent_var], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a dictionary to store R-squared scores\n",
    "r2_scores = {}\n",
    "mae_scores = {}\n",
    "mse_scores = {}\n",
    "\n",
    "# Iterate over each combination of independent variables\n",
    "for combo in combinations:\n",
    "    # Train an XGBoost regression model\n",
    "    model = xgb.XGBClassifier(objective='reg:squarederror', random_state=42) # Adjust hyperparameters as needed\n",
    "    model.fit(X_train[list(combo)], y_train)\n",
    "\n",
    "    # Make predictions using the test set\n",
    "    y_pred = model.predict(X_test[list(combo)])\n",
    "\n",
    "    # Calculate R-squared score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Store the R-squared score in a dictionary\n",
    "    r2_scores[combo] = r2\n",
    "    mae_scores[combo] = mae\n",
    "    mse_scores[combo] = mse\n",
    "\n",
    "# Find the combination with the highest R-squared score\n",
    "best_combo = max(r2_scores, key=r2_scores.get)\n",
    "\n",
    "#print(\"Best combination of independent variables:\", best_combo)\n",
    "#print(\"Highest R-squared score:\", r2_scores[best_combo])\n",
    "#print(\"Mean absolute error:\", mae_scores[best_combo])\n",
    "#print(\"Mean squared error:\", mse_scores[best_combo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination of independent variables: ('temperature', 'humidity', 'pressure', 'tvoc')\n",
      "Highest R-squared score: 0.6134782471496891\n",
      "Mean Squared Error - Unnormalized: 8088.668153445924\n",
      "Mean Absolute Error - Unnormalized: 58.25132065575764\n",
      "Mean Squared Error: 0.0009671201704714494\n",
      "Mean Absolute Error: 0.02014222705939061\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[independent_vars], df[dependent_var], test_size=0.2, random_state=42)\n",
    "\n",
    "summer_min = df_summer.min()\n",
    "summer_max = df_summer.max()\n",
    "\n",
    "r2_best_scores = {}\n",
    "mae_best_scores = {}\n",
    "mse_best_scores = {}\n",
    "\n",
    "best_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "best_model.fit(X_train[list(best_combo)], y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test[list(best_combo)])\n",
    "\n",
    "r2_best = r2_score(y_test, y_pred)\n",
    "mae_best = mean_absolute_error(y_test, y_pred)\n",
    "mse_best = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "mse_unnormalized = mse_best * (summer_max[\"radon\"] - summer_min[\"radon\"])**2\n",
    "mae_unnormalized = mae_best * (summer_max[\"radon\"] - summer_min[\"radon\"])\n",
    "\n",
    "print(\"Best combination of independent variables:\", best_combo)\n",
    "print(\"Highest R-squared score:\", r2_best)\n",
    "print(\"Mean Squared Error - Unnormalized:\", mse_unnormalized)\n",
    "print(\"Mean Absolute Error - Unnormalized:\", mae_unnormalized)\n",
    "print(\"Mean Squared Error:\", mse_best)\n",
    "print(\"Mean Absolute Error:\", mae_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting new Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted radon concentration 322.53340280056\n"
     ]
    }
   ],
   "source": [
    "summer_min = df_summer.min()\n",
    "summer_max = df_summer.max()\n",
    "\n",
    "independent_min = df_summer.drop(columns=[\"radon\"]).min()\n",
    "independent_max = df_summer.drop(columns=[\"radon\"]).max()\n",
    "\n",
    "new_data = {\"temperature\": 25, \"humidity\": 50, \"pressure\": 1017, \"tvoc\": 2}\n",
    "\n",
    "new_data_df = pd.DataFrame(new_data, index=[0])\n",
    "\n",
    "new_data_normalized = (new_data_df - independent_min) / (independent_max - independent_min)\n",
    "\n",
    "prediction = best_model.predict(new_data_normalized.values.reshape(1, -1))[0]\n",
    "##prediction = best_model.predict(pd.DataFrame([new_data_normalized])[list(best_combo)])\n",
    "\n",
    "unnormalized_prediction = prediction * (summer_max[\"radon\"] - summer_min[\"radon\"]) + summer_min[\"radon\"]\n",
    "\n",
    "print(\"Predicted radon concentration\", unnormalized_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting New Data: Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_radon(temp, humidity, pressure, tvoc):\n",
    "    summer_min = df_summer.min()\n",
    "    summer_max = df_summer.max()\n",
    "\n",
    "    independent_min = df_summer.drop(columns=[\"radon\"]).min()\n",
    "    independent_max = df_summer.drop(columns=[\"radon\"]).max()\n",
    "\n",
    "    new_data = {\"temperature\": temp, \"humidity\": humidity, \"pressure\": pressure, \"tvoc\": tvoc}\n",
    "\n",
    "    new_data_df = pd.DataFrame(new_data, index=[0])\n",
    "\n",
    "    new_data_normalized = (new_data_df - independent_min) / (independent_max - independent_min)\n",
    "\n",
    "    prediction = best_model.predict(new_data_normalized.values.reshape(1, -1))[0]\n",
    "    ##prediction = best_model.predict(pd.DataFrame([new_data_normalized])[list(best_combo)])\n",
    "\n",
    "    unnormalized_prediction = prediction * (summer_max[\"radon\"] - summer_min[\"radon\"]) + summer_min[\"radon\"]\n",
    "\n",
    "    print(\"Predicted radon concentration\", unnormalized_prediction)\n",
    "    return unnormalized_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted radon concentration 322.53340280056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "322.53340280056"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_radon(25, 50, 1017, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
